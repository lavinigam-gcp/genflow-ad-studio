{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtWMS2JLNltx"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# Author: sjangbahadur@"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-genai\n",
        "!pip install pandas\n",
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "id": "z9LrXyPnNpE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "z9KCnVTqNtgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c4046af"
      },
      "source": [
        "import pandas as pd\n",
        "from google.cloud import storage\n",
        "import os\n",
        "\n",
        "# Specify the path to your XLSX file\n",
        "# If the file is not in the current environment, please upload it to the Colab environment first.\n",
        "# Example: file_path = 'your_file_name.xlsx'\n",
        "file_path = \"Bulk Marketing Generation.xlsx\" # @param {type:\"string\"}\n",
        "\n",
        "# Check if the file path is provided\n",
        "if file_path:\n",
        "    # Load the XLSX file into a pandas DataFrame\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Display the first few rows of the DataFrame to verify\n",
        "    print(\"DataFrame loaded successfully. First 5 rows:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Please provide the path to your XLSX file in the 'file_path' variable.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "def format_json_response(response_text, folder_path):\n",
        "  print(response_text)\n",
        "  response_text_temp = re.sub(r\"json\", \"\", response_text)\n",
        "  response_text_temp = re.sub(r\"```\", \"\", response_text_temp)\n",
        "  json_response = json.loads(response_text_temp)\n",
        "  filename = os.path.join(folder_path ,\"output.json\")\n",
        "  print(filename)\n",
        "  # Open the file in write mode ('w') and use json.dump() to write the data\n",
        "  with open(filename, 'w') as file:\n",
        "     json.dump(json_response, file, indent=4) # 'indent=4' for pretty-printing with 4 spaces\n",
        "\n",
        "  print(f\"JSON data successfully written to '{filename}'\")\n",
        "  return json_response\n",
        "\n",
        "def upload_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the Google Cloud Storage bucket.\"\"\"\n",
        "    # Initialize a client\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    gcs_path = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
        "    print(f\"File {source_file_name} uploaded to {gcs_path}\")\n",
        "    return gcs_path"
      ],
      "metadata": {
        "id": "HJOk5sa146ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"<PROJECT_ID>\" # @param {type:\"string\"}\n",
        "region = \"global\" # @param {type:\"string\"}\n",
        "GCS_BUCKET_NAME = \"<GCS_BUCKET_NAME>\" # @param {type:\"string\"}\n",
        "VEO_MODEL_ID = \"veo-3.1-generate-preview\" # @param {type:\"string\"}\n",
        "GEMINI_MODEL = \"gemini-3-pro-preview\" # @param {type:\"string\"}\n",
        "IMAGE_MODEL = \"gemini-3-pro-image-preview\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "i32AS-C05O90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "import os\n",
        "import requests\n",
        "import io\n",
        "from io import BytesIO\n",
        "\n",
        "from IPython.display import Image, Markdown, display\n",
        "from PIL import Image as PIL_Image\n",
        "from google import genai\n",
        "from google.genai.types import GenerateContentConfig, Part\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import time\n",
        "\n",
        "client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=project_id,\n",
        "      location=region,\n",
        "  )\n",
        "\n",
        "def generate_marketing_content(product_name, specs, product_image_bytes):\n",
        "\n",
        "  msg1_text1 = types.Part.from_text(text=f\"\"\"SYSTEM:```You are an award-winning Advertising Director and Creative Copywriter specializing in high-conversion short-form video content.\n",
        "  Your expertise lies in creating 30-second commercials that utilize realistic AI avatars to build trust and explain complex products simply.\n",
        "  Your goal is to take a product name, its specifications, and a product image URL, and transform them into a structured JSON payload that serves as a programmatic blueprint for video generation.\n",
        "  You prioritize realism, clarity, and engagement.```\n",
        "  INSTRUCTION:```Based on the provided {product_name}, {specs}, and product image given below, generate a detailed 30+ second video production script in strict JSON format.\n",
        "  The video must be broken down into sequential scenes (approx 5-6 scenes, totaling 30+ seconds).\n",
        "  Constraints:\n",
        "  1. JSON Only: Do not include conversational text outside the JSON object.\n",
        "  2. Timing: The sum of all `duration_seconds` must equal 30.\n",
        "  3. Logic: Ensure smooth transitions between scenes.\n",
        "  4. Image Usage: You must explicitly describe how the provided product image is visually integrated into every scene.\n",
        "  5. Scripting: Translate technical {{specs}} into user-centric benefits.```\n",
        "  Product_image:\"\"\")\n",
        "  msg1_text2 = types.Part.from_text(text=\"\"\"Output Format:```Return a single JSON object with the following structure:\n",
        "  {\n",
        "     \"video_title\": \"string\",\n",
        "     \"total_duration\": 30,\n",
        "     \"avatar_profile\": {\n",
        "       \"gender\": \"string\",\n",
        "       \"age_range\": \"string\",\n",
        "       \"attire\": \"string (professional yet approachable)\",\n",
        "       \"tone_of_voice\": \"string\",\n",
        "       \"visual_description\": \"Detailed physical description of the avatar to ensure consistency across scenes. Make background white color.\"\n",
        "      },\n",
        "      \"scenes\": [\n",
        "        {\n",
        "        \"scene_number\": 1,\n",
        "        \"duration_seconds\": 8,\n",
        "        \"scene_type\": \"e.g., The Hook, The Problem, The Solution\",\n",
        "        \"visual_background\": \"Detailed description of the environment.\",\n",
        "        \"avatar_action\": \"Specific gestures or movements.\",\n",
        "        \"product_visual_integration\": \"How the product_image_url is displayed (e.g., 'Holographic overlay next to avatar', 'Picture-in-Picture top right', 'Avatar holding a tablet displaying the image').\",\n",
        "        \"script_dialogue\": \"The crisp exact spoken words which fits within max 8 sec.\"\n",
        "        }\n",
        "      ]\n",
        "    }```\"\"\")\n",
        "  image1 = types.Part.from_bytes(data=product_image_bytes,\n",
        "                           mime_type=\"image/*\")\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        msg1_text1,\n",
        "        image1,\n",
        "        msg1_text2\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model = GEMINI_MODEL,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "  )\n",
        "  #print(response.text)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "z3r5R4JK478m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_name):\n",
        "  file_content = \"\"\n",
        "  with open(file_name, \"rb\") as f:\n",
        "    file_content = f.read()\n",
        "  return file_content\n",
        "\n",
        "def generate_story_board_images(text_prompt, storyboard_file_name, avatar_image=None, product_image=None):\n",
        "  parts = []\n",
        "  if avatar_image:\n",
        "    msg1_image1 = types.Part.from_uri(\n",
        "        file_uri=avatar_image,\n",
        "        mime_type=\"image/*\",\n",
        "    )\n",
        "    parts.append(msg1_image1)\n",
        "  if product_image:\n",
        "    msg1_image2 = types.Part.from_uri(\n",
        "        file_uri=product_image,\n",
        "        mime_type=\"image/*\",\n",
        "    )\n",
        "    parts.append(msg1_image2)\n",
        "  parts.append(types.Part.from_text(text=text_prompt))\n",
        "\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=parts\n",
        "    ),\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 32768,\n",
        "    response_modalities = [\"IMAGE\"],\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    image_config=types.ImageConfig(\n",
        "      aspect_ratio=\"9:16\",\n",
        "      image_size=\"1K\",\n",
        "      output_mime_type=\"image/png\",\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model=IMAGE_MODEL,\n",
        "    contents=contents,\n",
        "    config=generate_content_config\n",
        "  )\n",
        "\n",
        "  for part in response.candidates[0].content.parts:\n",
        "    if part.text:\n",
        "        display(Markdown(part.text))\n",
        "    if part.inline_data:\n",
        "        with open(storyboard_file_name, 'wb') as f:\n",
        "            f.write(part.inline_data.data)\n",
        "        print(f\"Image saved to {storyboard_file_name}\")\n",
        "        display(Image(data=part.inline_data.data, width=500))"
      ],
      "metadata": {
        "id": "E0x1ffSzBhPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def storyboard_quality_check(reference_avatar_image, reference_product_image, storyboard_image):\n",
        "  msg1_text1 = types.Part.from_text(text=\"\"\"SYSTEM:```You are an expert Ad Video Director and Visual Continuity Specialist with a keen eye for detail. Your role is to perform rigorous quality assurance on video storyboards to ensure strict consistency with brand assets. You have an exceptional ability to detect subtle discrepancies in facial features, clothing details, product packaging, logos, and color grading. You evaluate visual inputs objectively and provide structured, data-driven feedback in JSON format. Your goal is to ensure that the character (avatar) and the merchandise (product) in the storyboard are identical to their respective references.```\n",
        "INSTRUCTION:```Analyze the provided input images:\n",
        "(1) Reference Avatar\n",
        "(2) Reference Product and\n",
        "(3) Storyboard Image.\n",
        "Perform a comparative analysis to validate the visual consistency.\n",
        "### STEPS:\n",
        "1. Avatar Analysis:\n",
        "\t- Compare the character in the Storyboard Image against the Reference Avatar.\n",
        "\t- Scrutinize facial features, hair style/color, age, gender, ethnicity, and clothing style.\n",
        "\t- Determine if the identity is preserved or if there are hallucinations/distortions.\n",
        "2. Product Analysis:\n",
        "\t- Compare the object/product in the Storyboard Image against the Reference Product.\n",
        "\t- Check for logo accuracy, spelling of text, color codes, shape, and packaging details.\n",
        "\t- Ensure the product has not been morphed or replaced.\n",
        "3. Scoring & Reasoning:\n",
        "\t- Assign a consistency score from 0 to 100 for both the Avatar and the Product (where 100 is a pixel-perfect conceptual match and 0 is completely unrecognizable).\n",
        "\t- Provide a concise, specific reason for the score, highlighting exactly what matched or what failed (e.g., 'Face shape matches, but eye color is wrong' or 'Logo text is misspelled').```\n",
        "REFERENCE_AVATAR_IMAGE:\"\"\")\n",
        "  msg1_image1 = types.Part.from_bytes(\n",
        "      data=read_file(reference_avatar_image),\n",
        "      mime_type=\"image/*\",\n",
        "  )\n",
        "  msg1_image2 = types.Part.from_bytes(\n",
        "      data=read_file(reference_product_image),\n",
        "      mime_type=\"image/*\",\n",
        "  )\n",
        "  msg1_image3 = types.Part.from_bytes(\n",
        "      data=read_file(storyboard_image),\n",
        "      mime_type=\"image/*\",\n",
        "  )\n",
        "  msg1_text2 = types.Part.from_text(text=\"\"\"OUTPUT_FORMAT:\n",
        "You must return ONLY a raw JSON object with no markdown formatting or additional text. Use the following schema:\n",
        "```{\n",
        "\t\"avatar_validation\": {\n",
        "\t\t\"score\": <integer_0_to_100>,\n",
        "\t\t\"reason\": \"<detailed_explanation_string>\"\n",
        "\t},\n",
        "\t\"product_validation\": {\n",
        "\t\t\"score\": <integer_0_to_100>,\n",
        "\t\t\"reason\": \"<detailed_explanation_string>\"\n",
        "\t}\n",
        "}```\"\"\")\n",
        "\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        msg1_text1,\n",
        "        msg1_image1,\n",
        "        types.Part.from_text(text=\"\"\"REFERENCE_PRODUCT_IMAGE:\"\"\"),\n",
        "        msg1_image2,\n",
        "        types.Part.from_text(text=\"\"\"STORYBOARD_IMAGE:\"\"\"),\n",
        "        msg1_image3,\n",
        "        msg1_text2\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "  tools = [\n",
        "    types.Tool(google_search=types.GoogleSearch()),\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 65535,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    tools = tools,\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "      thinking_level=\"HIGH\",\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model = GEMINI_MODEL,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "  )\n",
        "  #print(response.text)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "feMTYs7JqMSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_scenes(prompt_text, video_file_path, reference_image=None):\n",
        "  # Optional parameters\n",
        "  negative_prompt = \"ugly, low quality\"\n",
        "  aspect_ratio = \"9:16\"\n",
        "  resolution = \"1080p\"\n",
        "  generate_audio = True\n",
        "  duration_seconds = 8\n",
        "  number_of_videos = 4\n",
        "\n",
        "  # Loading the image\n",
        "  if reference_image:\n",
        "    #im = PIL_Image.open(reference_image)\n",
        "    # converting the image to bytes\n",
        "    #image_bytes_io = io.BytesIO()\n",
        "    #im.save(image_bytes_io, format=im.format)\n",
        "    #image_bytes = image_bytes_io.getvalue()\n",
        "\n",
        "    operation = client.models.generate_videos(\n",
        "        model=VEO_MODEL_ID,\n",
        "        prompt=prompt_text,\n",
        "        image=types.Image(\n",
        "          gcs_uri=reference_image,\n",
        "          mime_type=\"image/*\",\n",
        "        ),\n",
        "        config=types.GenerateVideosConfig(\n",
        "          aspect_ratio=aspect_ratio,\n",
        "          resolution=resolution,\n",
        "          number_of_videos=number_of_videos,\n",
        "          duration_seconds=duration_seconds,\n",
        "          negative_prompt=negative_prompt,\n",
        "          generate_audio=generate_audio,\n",
        "          output_gcs_uri=video_file_path,\n",
        "        ),\n",
        "    )\n",
        "  else:\n",
        "    operation = client.models.generate_videos(\n",
        "        model=VEO_MODEL_ID,\n",
        "        prompt=prompt_text,\n",
        "        config=types.GenerateVideosConfig(\n",
        "          aspect_ratio=aspect_ratio,\n",
        "          resolution=resolution,\n",
        "          number_of_videos=number_of_videos,\n",
        "          duration_seconds=duration_seconds,\n",
        "          negative_prompt=negative_prompt,\n",
        "          generate_audio=generate_audio,\n",
        "          output_gcs_uri=video_file_path,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "  if operation.response:\n",
        "    print(operation.result.generated_videos[0].video.uri)\n",
        "    return operation.result.generated_videos\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "  # Waiting for the video(s) to be generated\n",
        "  #while not operation.done:\n",
        "  #    time.sleep(20)\n",
        "  #    operation = client.operations.get(operation)\n",
        "  #    print(operation)\n",
        "\n",
        "  #print(operation.result.generated_videos)\n",
        "\n",
        "  #for n, generated_video in enumerate(operation.result.generated_videos):\n",
        "  #  client.files.download(file=generated_video.video)\n",
        "  #  generated_video.video.save(f'{video_file_path}/videos_{n}.mp4') # Saves the video(s)\n",
        "  #  display(generated_video.video.show()) # Displays the video(s) in a notebook"
      ],
      "metadata": {
        "id": "aFrs4mvC-eA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_quality_check(video_gcs_path, reference_image_gcs_path):\n",
        "  msg1_text1 = types.Part.from_text(text=\"\"\"SYSTEM:```You are a veteran Film Director and VFX Quality Control Supervisor with over 20 years of experience in cinematic workflows and post-production. You possess an acute eye for detail, capable of spotting sub-pixel anomalies, temporal inconsistencies, and fidelity issues. Your task is to critique AI-generated or edited video content against reference asset with a rigorous standard for photorealism, continuity, and technical integrity. You communicate using technical cinematic terminology.```\n",
        "INSTRUCTION:```Analyze the provided video input in relation to the provided reference Image''. You must conduct a frame-by-frame analysis to detect any degradation in quality or logical fallacies.\n",
        "Evaluate the video based on the following five specific dimensions:\n",
        "1. Technical Distortion: Check for compression artifacts, screen tearing, aliasing, warping, or glitching.\n",
        "2. Cinematic Imperfections: Analyze lighting flickers, unnatural motion blur, grain inconsistencies, or color grading shifts that break the cinematic look.\n",
        "3. Avatar Consistency: Compare the video subject against the reference Image. Check for facial feature consistency, and anatomical correctness during movement.\n",
        "4. Product Consistency: Compare the object in the video against the Reference Image. Check for logo deformation, texture warping, scale issues, or color shifting.\n",
        "Scoring Criteria:\n",
        "- Provide a 'Quality Score' from 0 to 10 for each category (10 being perfect/flawless, 0 being unusable).\n",
        "Make sure to double check the reference image and video frames before generating the results.```\n",
        "VIDEO:\"\"\")\n",
        "  msg1_video1 = types.Part.from_uri(\n",
        "      file_uri=video_gcs_path,\n",
        "      mime_type=\"video/mp4\",\n",
        "      media_resolution={\"level\": \"media_resolution_high\"}\n",
        "  )\n",
        "  msg1_image1 = types.Part.from_uri(\n",
        "      file_uri=reference_image_gcs_path,\n",
        "      mime_type=\"image/*\",\n",
        "      media_resolution={\"level\": \"media_resolution_high\"}\n",
        "  )\n",
        "  msg1_text2 = types.Part.from_text(text=\"\"\"Output Format:```\n",
        "- Your response must be strictly in valid JSON format.\n",
        "- Do not include markdown formatting (like ```json) or conversational text outside the JSON object.\n",
        "- Use the following schema:\n",
        "{\n",
        "\t\"analysis_report\": {\n",
        "\t\t\"technical_distortion\": {\n",
        "\t\t\t\"score\": <0-10>,\n",
        "\t\t\t\"reasoning\": \"Detailed technical explanation of artifacts observed...\"\n",
        "\t\t},\n",
        "\t\t\"cinematic_imperfections\": {\n",
        "\t\t\t\"score\": <0-10>,\n",
        "\t\t\t\"reasoning\": \"Analysis of lighting, shutter angle, camera movements and grain...\"\n",
        "\t\t},\n",
        "\t\t\"avatar_consistency\": {\n",
        "\t\t\t\"score\": <0-10>,\n",
        "\t\t\t\"reasoning\": \"Comparison of facial feature consistency against reference...\"\n",
        "\t\t},\n",
        "\t\t\"product_consistency\": {\n",
        "\t\t\t\"score\": <0-10>,\n",
        "\t\t\t\"reasoning\": \"Assessment of brand asset fidelity and object geometry...\"\n",
        "\t\t},\n",
        "\t\t\"overall_verdict\": \"A summary statement regarding the video's usability for professional broadcast.\"\n",
        "\t}\n",
        "}```\"\"\")\n",
        "\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        msg1_text1,\n",
        "        msg1_video1,\n",
        "        types.Part.from_text(text=\"\"\"REFERENCE_IMAGE:\"\"\"),\n",
        "        msg1_image1,\n",
        "        msg1_text2\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "  tools = [\n",
        "    types.Tool(google_search=types.GoogleSearch()),\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 65535,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    tools = tools,\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "      thinking_level=\"HIGH\",\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  for chunk in client.models.generate_content_stream(\n",
        "    model = GEMINI_MODEL,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:\n",
        "        continue\n",
        "    print(chunk.text, end=\"\")\n"
      ],
      "metadata": {
        "id": "ZUY5V6G_jUvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f565fcf2"
      },
      "source": [
        "# Define the folder name for storing product images\n",
        "image_folder = \"product_images\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(image_folder):\n",
        "    os.makedirs(image_folder)\n",
        "    print(f\"Created folder: {image_folder}/\")\n",
        "\n",
        "product_data = []\n",
        "for index, row in df.iterrows():\n",
        "    product_name = row['Product Name']\n",
        "    specifications = row['Specifications']\n",
        "    image_urls = row['Public Image URL']\n",
        "    first_image_url = image_urls.split(',')[0].strip() if isinstance(image_urls, str) else image_urls\n",
        "\n",
        "    product_image_bytes = None\n",
        "    # Construct the full path for the local image file for the product\n",
        "    folder_path = os.path.join(image_folder, f\"product_{index}\")\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    product_local_image_path = os.path.join(folder_path, f\"product_image_{index}.jpeg\") # Original product image saved as jpeg\n",
        "    print(product_local_image_path)\n",
        "    if first_image_url:\n",
        "        try:\n",
        "            response = requests.get(first_image_url, stream=True)\n",
        "            response.raise_for_status() # Raise an exception for HTTP errors\n",
        "            product_image_bytes = io.BytesIO(response.content).getvalue()\n",
        "            with open(product_local_image_path, 'wb') as f:\n",
        "                f.write(product_image_bytes)\n",
        "            print(f\"Downloaded image for '{product_name}' from '{first_image_url}' and saved to '{product_local_image_path}'\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading image for '{product_name}' from '{first_image_url}': {e}\")\n",
        "            product_image_bytes = None # Ensure it's None if download fails\n",
        "\n",
        "    combined_string = f\"Product Name: {product_name}, Specifications: {specifications}\"\n",
        "\n",
        "    response_json = None\n",
        "    if product_image_bytes:\n",
        "        try:\n",
        "            print(f\"\\n--- Generating marketing content for {product_name} ---\")\n",
        "            response_json = format_json_response(generate_marketing_content(product_name, specifications, product_image_bytes), folder_path)\n",
        "\n",
        "            if response_json:\n",
        "                # --- New Steps Start Here ---\n",
        "\n",
        "                # 1. Generate unique avatar image\n",
        "                print(f\"\\n--- Generating avatar image for {product_name} ---\")\n",
        "                avatar_profile = response_json['avatar_profile']\n",
        "                avatar_prompt = json.dumps(avatar_profile)\n",
        "                avatar_image_filename = os.path.join(folder_path, f\"avatar_{index}.png\") # Generated image is png\n",
        "                generate_story_board_images(avatar_prompt, avatar_image_filename)\n",
        "\n",
        "                gcs_avatar_image_destination_blob = f\"bajaj_marketing_workflow/product_{index}/{os.path.basename(avatar_image_filename)}\"\n",
        "                gcs_avatar_image_path = upload_to_gcs(GCS_BUCKET_NAME, avatar_image_filename, gcs_avatar_image_destination_blob)\n",
        "                print(gcs_avatar_image_path)\n",
        "\n",
        "                gcs_product_image_destination_blob = f\"bajaj_marketing_workflow/product_{index}/{os.path.basename(product_local_image_path)}\"\n",
        "                gcs_product_image_path = upload_to_gcs(GCS_BUCKET_NAME, product_local_image_path, gcs_product_image_destination_blob)\n",
        "                print(gcs_product_image_path)\n",
        "\n",
        "                # 2. Generate storyboard images for each scene & 3. Perform storyboard quality checks\n",
        "                print(f\"\\n--- Generating storyboard images and performing QC for {product_name} ---\")\n",
        "                for scene in response_json['scenes']:\n",
        "                    scene_image_filename = os.path.join(folder_path, f\"scene_{index}_{scene['scene_number']}.png\") # Generated image is png\n",
        "                    storyboard_prompt = f\"Background: {scene['visual_background']}, avatar_action : {scene['avatar_action']}, product_integration: {scene['product_visual_integration']}.\"\n",
        "                    generate_story_board_images(storyboard_prompt, scene_image_filename, avatar_image=gcs_avatar_image_path, product_image=gcs_product_image_path)\n",
        "\n",
        "                    gcs_scene_image_destination_blob = f\"bajaj_marketing_workflow/product_{index}/{os.path.basename(scene_image_filename)}\"\n",
        "                    gcs_scene_image_path = upload_to_gcs(GCS_BUCKET_NAME, scene_image_filename, gcs_scene_image_destination_blob)\n",
        "\n",
        "                    # Perform storyboard quality check\n",
        "                    print(f\"--- Performing storyboard quality check for scene {scene['scene_number']} ---\")\n",
        "                    try:\n",
        "                        # storyboard_quality_check returns a JSON string\n",
        "                        storyboard_qc_result = storyboard_quality_check(avatar_image_filename, product_local_image_path, scene_image_filename)\n",
        "                        print(f\"Storyboard QC Result for scene {scene['scene_number']}:\\n{storyboard_qc_result}\")\n",
        "                    except Exception as qc_e:\n",
        "                        print(f\"Error during storyboard quality check for scene {scene['scene_number']}: {qc_e}\")\n",
        "\n",
        "\n",
        "                    # 4. Generate a promotional video\n",
        "                    print(f\"\\n--- Generating promotional video for {product_name} ---\")\n",
        "                    video_output_folder = os.path.join(folder_path, \"generated_videos\")\n",
        "                    os.makedirs(video_output_folder, exist_ok=True)\n",
        "                    video_prompt = f\"scene_type: {scene['scene_type']}, tone_of_voice: {avatar_profile['tone_of_voice']}, avatar_action : {scene['avatar_action']}, visual_background: {scene['visual_background']}, product_visual_integration: {scene['product_visual_integration']}, Dialogue:{scene['script_dialogue']}\"\n",
        "                    gcs_video_destination_blob = f\"gs://{GCS_BUCKET_NAME}/bajaj_marketing_workflow/product_{index}\"\n",
        "                    gcs_video_paths = generate_video_scenes(video_prompt, gcs_video_destination_blob, reference_image=gcs_scene_image_path)\n",
        "                    # Assuming the generated video is named videos_0.mp4 inside the video_output_folder\n",
        "                    #generated_video_local_path = os.path.join(video_output_folder, \"videos_0.mp4\")\n",
        "                    for video_path in gcs_video_paths:\n",
        "                      # 5. Upload the generated video and original product image to GCS\n",
        "                      print(f\"\\n--- Uploaded video to GCS: {video_path.video.uri} ---\")\n",
        "                      #gcs_video_destination_blob = f\"bajaj_marketing_workflow/product_{index}/{os.path.basename(generated_video_local_path)}\"\n",
        "                      #gcs_video_path = upload_to_gcs(GCS_BUCKET_NAME, generated_video_local_path, gcs_video_destination_blob)\n",
        "\n",
        "                      # 6. Perform a quality check on the generated video\n",
        "                      print(f\"\\n--- Performing video quality check for {product_name} ---\")\n",
        "                      try:\n",
        "                          # video_quality_check function prints its output directly\n",
        "                          video_quality_check(video_path.video.uri, gcs_scene_image_path)\n",
        "                      except Exception as vid_qc_e:\n",
        "                          print(f\"Error during video quality check: {vid_qc_e}\")\n",
        "\n",
        "                # --- New Steps End Here ---\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during processing for '{product_name}': {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc() # Print full traceback for debugging\n",
        "            print(\"This could be due to issues with API calls or file operations.\")\n",
        "    else:\n",
        "        print(f\"Skipping processing for '{product_name}' due to missing or failed image download.\")\n",
        "\n",
        "    product_data.append(combined_string)\n",
        "\n",
        "print(f\"Extracted {len(product_data)} product entries.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcDx1fxi3C7Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}